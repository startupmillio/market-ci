name: Market deploy template workflow

on:
  workflow_call:
    inputs:
      codeSrc:
        required: false
        type: string
        default: "."
      testsOnly:
        required: false
        type: boolean
        default: false
      PROJECT_NAME:
        required: false
        type: string
      AWS_REGION:
        required: false
        type: string
      ECR_REPOSITORY:
        required: false
        type: string
    secrets:
      AWS_ACCESS_KEY_ID:
        required: false
      AWS_SECRET_ACCESS_KEY:
        required: false

jobs:
  Black:
    name: Black Test
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: psf/black@stable
        with:
          options: "--check --verbose --diff --color"
          src: ${{ inputs.codeSrc }}
          version: "22.3.0"

  Pytest:
    runs-on: ubuntu-latest
    timeout-minutes: 10

    services:
      db_service:
        image: postgres
        env:
          POSTGRES_USER: postgres
          POSTGRES_DB: postgres
          POSTGRES_PASSWORD: postgres
        # Set health checks to wait until postgres has started
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          # Maps tcp port 5432 on service container to the host
          - 5432:5432
    defaults:
      run:
        working-directory: ${{ inputs.codeSrc }}
    steps:
      - name: Check out repository code
        uses: actions/checkout@v2

      # Setup Python (faster than using Python container)
      - name: Setup Python
        uses: actions/setup-python@v2
        with:
          python-version: "3.10"

      - name: Install pipenv
        run: |
          python -m pip install --upgrade pipenv wheel
      - id: cache-pipenv
        uses: actions/cache@v1
        with:
          path: ~/.local/share/virtualenvs
          key: ${{ runner.os }}-pipenv-${{ hashFiles('**/Pipfile.lock') }}

      - name: Install dependencies
        if: steps.cache-pipenv.outputs.cache-hit != 'true'
        run: |
          pipenv install --deploy --dev
      - name: Setup db
        run: |
          pipenv run python -m tests.setup_test_db
        env:
          TEST_DB_HOST: localhost
          TEST_DB_NAME: postgres
          TEST_DB_PASS: postgres
          TEST_DB_PORT: 5432
          TEST_DB_USER: postgres
      - name: Run test suite
        run: |
          pipenv run pytest
        env:
          TEST_DB_HOST: localhost
          TEST_DB_NAME: postgres
          TEST_DB_PASS: postgres
          TEST_DB_PORT: 5432
          TEST_DB_USER: postgres

  Infrastructure:
    runs-on: ubuntu-latest
    needs: [Black, Pytest]
    steps:
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v1
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ inputs.AWS_REGION }}
    - name: Check if S3 Bucket exists
      run: |
        BUCKET_EXISTS=$(aws s3api head-bucket --bucket ${{ inputs.PROJECT_NAME }}-s3-terraform 2>&1)
        if [[ "$BUCKET_EXISTS" != "" ]]; then aws s3api create-bucket \
        --bucket ${{ inputs.PROJECT_NAME }}-s3-terraform --region ${{ inputs.AWS_REGION }};
        echo "S3 Bucket does not exist, creating one for you.";
        else
        echo "S3 Bucket already exists, moving forward."
        fi
  

  Build:
    if: inputs.testsOnly != true
    name: Build image
    runs-on: ubuntu-latest
    needs: [Black, Pytest, Infrastructure]

    defaults:
      run:
        working-directory: ${{ inputs.codeSrc }}

    steps:
    - uses: actions/checkout@v2
    - name: Install kubectl
      uses: azure/setup-kubectl@v2
      with:
        version: '1.24' # default is latest stable
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v1
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ inputs.AWS_REGION }}
    
    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v1

    - name: Install pipenv
      run: |
        python -m pip install --upgrade pipenv wheel
    - id: cache-pipenv
      uses: actions/cache@v1
      with:
        path: ~/.local/share/virtualenvs
        key: ${{ runner.os }}-pipenv-${{ hashFiles('**/Pipfile.lock') }}

    - name: Install dependencies
      if: steps.cache-pipenv.outputs.cache-hit != 'true'
      run: |
        pipenv install --deploy --dev

    - name: Build, tag, and push image to Amazon ECR
      env:
        ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
        ECR_REPOSITORY: ${{ inputs.ECR_REPOSITORY }}
        IMAGE_TAG: ${{ github.sha }}
      run: |
        export DOCKER_BUILDKIT=1
        docker build -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG -t latest .
        docker push -a $ECR_REGISTRY/$ECR_REPOSITORY