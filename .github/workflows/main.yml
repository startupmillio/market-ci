name: Market deploy template workflow

on:
  workflow_call:
    inputs:
      codeSrc:
        required: true
        type: string
      AWS_ACCESS_KEY_ID:
        required: true
        type: string
      AWS_SECRET_ACCESS_KEY:
        required: true
        type: string
      ECR_REPOSITORY:
        required: true
        type: string
      AWS_REGION:
        required: true
        type: string

jobs:
  Black:
    name: Black Test
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: psf/black@stable
        with:
          options: "--check --verbose --diff --color"
          src: ${{ inputs.codeSrc }}
          version: "22.3.0"

  Pytest:
    runs-on: ubuntu-latest
    timeout-minutes: 10

    services:
      db_service:
        image: postgres
        env:
          POSTGRES_USER: postgres
          POSTGRES_DB: postgres
          POSTGRES_PASSWORD: postgres
        # Set health checks to wait until postgres has started
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          # Maps tcp port 5432 on service container to the host
          - 5432:5432
    defaults:
      run:
        working-directory: ${{ inputs.codeSrc }}
    steps:
      - name: Check out repository code
        uses: actions/checkout@v2

      # Setup Python (faster than using Python container)
      - name: Setup Python
        uses: actions/setup-python@v2
        with:
          python-version: "3.10"

      - name: Install pipenv
        run: |
          python -m pip install --upgrade pipenv wheel
      - id: cache-pipenv
        uses: actions/cache@v1
        with:
          path: ~/.local/share/virtualenvs
          key: ${{ runner.os }}-pipenv-${{ hashFiles('**/Pipfile.lock') }}

      - name: Install dependencies
        if: steps.cache-pipenv.outputs.cache-hit != 'true'
        run: |
          pipenv install --deploy --dev
      - name: Setup db
        run: |
          pipenv run python -m tests.setup_test_db
        env:
          TEST_DB_HOST: localhost
          TEST_DB_NAME: postgres
          TEST_DB_PASS: postgres
          TEST_DB_PORT: 5432
          TEST_DB_USER: postgres
      - name: Run test suite
        run: |
          pipenv run pytest
        env:
          TEST_DB_HOST: localhost
          TEST_DB_NAME: postgres
          TEST_DB_PASS: postgres
          TEST_DB_PORT: 5432
          TEST_DB_USER: postgres

  Build:
    name: Build image
    runs-on: ubuntu-latest

    steps:
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v1
      with:
        aws-access-key-id: ${{ inputs.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ inputs.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ inputs.AWS_REGION }}
    
    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v1

    - name: Build, tag, and push image to Amazon ECR
      env:
        ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
        ECR_REPOSITORY: ${{ inputs.ECR_REPOSITORY }}
        IMAGE_TAG: ${{ github.sha }}
      run: |
      docker build -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG ${{ inputs.codeSrc }}
      docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG