name: Marketplace-boilerplate CI/CD workflow

on:
  workflow_call:
    inputs:
      codeSrc: # Source code path. Default is '.'
        required: false
        type: string
        default: "."
      testsOnly: # Prevents other jobs except 'test jobs' to run if true.
        required: false
        type: boolean
        default: false
      skipTests: #Skips tests if true
        required: false
        type: boolean
        default: true ##!!!! DONT FORGET TO CORRECT
      skipBuild:
        required: false
        type: boolean
        default: true ##!!!! DONT FORGET TO CORRECT
      PROJECT_NAME: # Project name defines aws resources prefix to deploy and manage
        required: false
        type: string
      PROJECT_ENV: # Project environment (dev, qa, staging, prod). Also affects some aws resources prefixes and tags
        required: false
        type: string
      SERVICE_NAME:
        required: false
        type: string
      AWS_REGION: # AWS Region to deploy resources in.
        required: false
        type: string
      VPC_CIDR: # VPC CIDR for kubernetes to use
        required: false
        type: string
      ROUTE53_ZONE: # Zone name to create dns records in
        required: false
        type: string
        
    secrets:
      AWS_ACCESS_KEY_ID:
        required: false
      AWS_SECRET_ACCESS_KEY:
        required: false

env:
  BUCKET_NAME: ${{ inputs.PROJECT_NAME }}-terraform
  ECR_NAME: ${{ inputs.PROJECT_NAME}}-${{ inputs.SERVICE_NAME }}-${{ inputs.PROJECT_ENV }}
  EKS_NAME: ${{ inputs.PROJECT_NAME }}-${{ inputs.PROJECT_ENV }}
  DIR_TF_ENVIRONMENT: ./Terraform/Environment
  DIR_TF_PROJECT: ./Terraform/Project
  DIR_TF_SERVICE: ./Terraform/Service
  PATH_TF_BACKEND_PROJECT: "terraform/${{ inputs.PROJECT_NAME }}/PROJECT/terraform.tfstate"
  PATH_TF_BACKEND_ENV: "terraform/${{ inputs.PROJECT_NAME }}/ENV/${{ inputs.PROJECT_ENV }}/terraform.tfstate"
  PATH_TF_BACKEND_SERVICE: "terraform/${{ inputs.PROJECT_NAME }}/ENV/${{ inputs.PROJECT_ENV }}/${{ inputs.SERVICE_NAME }}"
  PROJECT_VPC_ID: PLACEHOLDER
  PROJECT_VPC_PRIVATE_SUBNETS: PLACEHOLDER

jobs:
  Black:
    if: ${{ !inputs.skipTests }}
    name: Black Test
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: psf/black@stable
        with:
          options: "--check --verbose --diff --color"
          src: ${{ inputs.codeSrc }}
          version: "22.3.0"

  Pytest:
    if: ${{ !inputs.skipTests }}
    runs-on: ubuntu-latest
    timeout-minutes: 10

    services:
      db_service:
        image: postgres
        env:
          POSTGRES_USER: postgres
          POSTGRES_DB: postgres
          POSTGRES_PASSWORD: postgres
        # Set health checks to wait until postgres has started
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          # Maps tcp port 5432 on service container to the host
          - 5432:5432
    defaults:
      run:
        working-directory: ${{ inputs.codeSrc }}
    steps:
      - name: Check out repository code
        uses: actions/checkout@v2

      # Setup Python (faster than using Python container)
      - name: Setup Python
        uses: actions/setup-python@v2
        with:
          python-version: "3.10"

      - name: Install pipenv
        run: |
          python -m pip install --upgrade pipenv wheel
      - id: cache-pipenv
        uses: actions/cache@v2
        with:
          path: ~/.local/share/virtualenvs
          key: ${{ runner.os }}-pipenv-${{ hashFiles('**/Pipfile.lock') }}

      - name: Install dependencies
        if: steps.cache-pipenv.outputs.cache-hit != 'true'
        run: |
          pipenv install --deploy --dev
      - name: Setup db
        run: |
          pipenv run python -m tests.setup_test_db
        env:
          TEST_DB_HOST: localhost
          TEST_DB_NAME: postgres
          TEST_DB_PASS: postgres
          TEST_DB_PORT: 5432
          TEST_DB_USER: postgres
      - name: Run test suite
        run: |
          pipenv run pytest
        env:
          TEST_DB_HOST: localhost
          TEST_DB_NAME: postgres
          TEST_DB_PASS: postgres
          TEST_DB_PORT: 5432
          TEST_DB_USER: postgres

  Infrastructure-S3-ECR:
    runs-on: ubuntu-latest
    needs: [Black, Pytest]
    if: |
      always() &&
      inputs.testsOnly != true ||
      (needs.Black.result == 'success' && needs.Pytest.result == 'success') ||
      (needs.Black.result == 'skipped' && needs.Pytest.result == 'skipped')

    steps:
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v1
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ inputs.AWS_REGION }}

    - name: Check for existing S3, ECR
      id: check-s3-ecr
      shell: bash
      # Checking if S3 Bucket & ECR Repository with same names already
      # exist and setting result as outputs for this step.
      run: |
        if [[ $(aws s3api head-bucket --bucket ${{ env.BUCKET_NAME }} 2>&1) != "" ]]; then echo "S3 Bucket does not exist, will create one for you.";
        echo '::set-output name=BUCKET_EXISTS::false'
        else
        echo "S3 Bucket already exists, skipping AWS S3 Bucket creation step..";
        echo '::set-output name=BUCKET_EXISTS::true'
        fi
        if [[ $(aws ecr describe-repositories --repository-names ${{ env.ECR_NAME }} 2>&1) != *"RepositoryNotFoundException"* ]];
        then echo "ECR repository already exists, skipping AWS ECR creation step..";
        echo '::set-output name=ECR_EXISTS::true'
        else
        echo "ECR repository does not exist, will create one for you.";
        echo '::set-output name=ECR_EXISTS::false';
        fi

    - name: Create S3 Bucket
      if: steps.check-s3-ecr.outputs.BUCKET_EXISTS == 'false'
      shell: bash
      # Creating S3 Bucket for terraform backend if it does not exist.
      run: |
        aws s3api create-bucket --bucket ${{ env.BUCKET_NAME }} --region ${{ inputs.AWS_REGION }}

    - name: Create ECR repository
      if: steps.check-s3-ecr.outputs.ECR_EXISTS == 'false'
      # Creating ECR Repository for project if it does not exist.
      run: |
        aws ecr create-repository \
        --repository-name ${{ env.ECR_NAME }} \
        --image-scanning-configuration scanOnPush=true

  Build:
    if: |
      always() &&
      inputs.skipBuild != true ||
      inputs.testsOnly != true ||
      (needs.Black.result == 'success' && needs.Pytest.result == 'success') ||
      (needs.Black.result == 'skipped' && needs.Pytest.result == 'skipped')
    name: Build image
    runs-on: ubuntu-latest
    needs: [Infrastructure-S3-ECR]

    defaults:
      run:
        working-directory: ${{ inputs.codeSrc }}

    steps:
    - uses: actions/checkout@v2
    - name: Install kubectl
      uses: azure/setup-kubectl@v2.0
      with:
        version: 'latest'

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v1
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ inputs.AWS_REGION }}
    
    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v1

    - name: Install pipenv
      run: |
        python -m pip install --upgrade pipenv wheel
    - id: cache-pipenv
      uses: actions/cache@v2
      with:
        path: ~/.local/share/virtualenvs
        key: ${{ runner.os }}-pipenv-${{ hashFiles('**/Pipfile.lock') }}

    - name: Install dependencies
      if: steps.cache-pipenv.outputs.cache-hit != 'true'
      run: |
        pipenv install --deploy --dev

    - name: Build, tag, and push image to Amazon ECR
      env:
        ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
        ECR_REPOSITORY: ${{ env.ECR_NAME }}
        IMAGE_TAG: ${{ github.sha }}
      #DOCKER_BUILDKIT=1 environment variable is required, otherwise build job is going to throw an error.
      run: |
        export DOCKER_BUILDKIT=1
        docker build -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG \
        -t $ECR_REGISTRY/$ECR_REPOSITORY:latest .
        docker push -a $ECR_REGISTRY/$ECR_REPOSITORY

  Deploy:
    runs-on: ubuntu-latest
    needs: [Pytest, Black, Build, Infrastructure-S3-ECR] # Dont forget to include build stage here later.
    if: |
      always() &&
      inputs.testsOnly != true ||
      (needs.Black.result == 'success' && needs.Pytest.result == 'success') ||
      (needs.Black.result == 'skipped' && needs.Pytest.result == 'skipped') ||
      (needs.Build.result == 'skipped') ||
      (needs.Build.result == 'success')
      
    steps:
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v1
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ inputs.AWS_REGION }}

    - name: Clone market-ci repository
      uses: actions/checkout@v3
      with:
        #Cloning repository with terraform code
        #Don't forget to change ref to main :)
        repository: startupmillio/market-ci
        ref: "BM-29" #change to main!!!

    - name: 'Terraform: modifying backend variables - Project'
      working-directory: ${{ env.DIR_TF_PROJECT }}
      # Terraform does not allow to parse variables to backend configuration
      # So we have to modify provider.tf file with our input parameters using sed.
      run: |
        sed -i 's/${github.project_name}/${{ inputs.PROJECT_NAME }}/' provider.tf
        sed -i 's/${github.project_env}/${{ inputs.PROJECT_ENV }}/' provider.tf
        sed -i 's/${github.region}/${{ inputs.AWS_REGION }}/' provider.tf
        sed -i 's/${github.bucket_name}/${{ env.BUCKET_NAME }}/' provider.tf
        sed -i 's|${github.bucket_key}|${{ env.PATH_TF_BACKEND_PROJECT }}|' provider.tf


    - name: Terraform - Project Infrasctructure
      working-directory: ${{ env.DIR_TF_PROJECT }}
      env:
        TERRAFORM_VARS_PROJECT: "-var 'project_region=${{ inputs.AWS_REGION }}' -var 'project_name=${{ inputs.PROJECT_NAME }}' \
        -var 'project_env=${{ inputs.PROJECT_ENV }}' -var 'vpc_cidr=${{ inputs.VPC_CIDR }}' \
        -var 'env_eks_name=${{ env.EKS_NAME }}'"
      run: |
        terraform init
        terraform validate
        terraform apply -auto-approve ${{ env.TERRAFORM_VARS_PROJECT }}
        PROJECT_VPC_ID="$(terraform output -raw project_vpc_id)"
        PROJECT_VPC_PRIVATE_SUBNETS="$(terraform output -raw project_vpc_private_subnets)"

    - name: 'Terraform: modifying backend variables - Environment'
      working-directory: ${{ env.DIR_TF_ENVIRONMENT }}
      # Terraform does not allow to parse variables to backend configuration
      # So we have to modify provider.tf file with our input parameters using sed.
      run: |
        sed -i 's/${github.project_name}/${{ inputs.PROJECT_NAME }}/' provider.tf
        sed -i 's/${github.project_env}/${{ inputs.PROJECT_ENV }}/' provider.tf
        sed -i 's/${github.region}/${{ inputs.AWS_REGION }}/' provider.tf
        sed -i 's/${github.bucket_name}/${{ env.BUCKET_NAME }}/' provider.tf
        sed -i 's|${github.bucket_key}|${{ env.PATH_TF_BACKEND_ENV }}|' provider.tf

    - name: Terraform - Environment infrastructure
      env:
        TERRAFORM_VARS_ENV: "-var 'project_region=${{ inputs.AWS_REGION }}' -var 'project_name=${{ inputs.PROJECT_NAME }}' \
        -var 'project_env=${{ inputs.PROJECT_ENV }}' -var 'vpc_cidr=${{ inputs.VPC_CIDR }}' \
        -var 'route53_zone=${{ inputs.ROUTE53_ZONE }}' -var 'env_eks_name=${{ env.EKS_NAME }}' \
        -var 'service_name=${{ inputs.SERVICE_NAME }}' -var 'project_vpc_id=${{ env.PROJECT_VPC_ID }}' \
        -var 'project_vpc_private_subnets=${{ env.PROJECT_VPC_PRIVATE_SUBNETS }}'"
      working-directory: ${{ env.DIR_TF_ENVIRONMENT }}
      run: |
        terraform init
        terraform validate
        terraform apply -auto-approve ${{ env.TERRAFORM_VARS_ENV }}

    
